import React, { useState, useEffect } from 'react';
import { StyleSheet, Text, View, TouchableOpacity, SafeAreaView, Dimensions, ActivityIndicator } from 'react-native';
import Voice from '@react-native-voice/voice';
import * as Speech from 'expo-speech';
import { getNextQuestion, generateMemoir } from '../services/aiService';
import { saveMemoir } from '../services/storageService';

const { width } = Dimensions.get('window');

const DialogueScreen = ({ route, navigation }) => {
  const { scene } = route.params;

  // çŠ¶æ€ç®¡ç†
  const [conversationHistory, setConversationHistory] = useState([]);
  const [currentAIQuestion, setCurrentAIQuestion] = useState('');
  const [userSpeech, setUserSpeech] = useState('');
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(true); // æ˜¯å¦æ­£åœ¨ç­‰å¾…AIå“åº”
  const [error, setError] = useState('');

  // åˆå§‹åŒ–
  useEffect(() => {
    // è®¾ç½®Voiceçš„äº‹ä»¶ç›‘å¬å™¨
    Voice.onSpeechStart = onSpeechStart;
    Voice.onSpeechEnd = onSpeechEnd;
    Voice.onSpeechError = onSpeechError;
    Voice.onSpeechResults = onSpeechResults;
    
    // å¼€å§‹ç¬¬ä¸€è½®å¯¹è¯
    const firstQuestion = `å¥½çš„ï¼Œè®©æˆ‘ä»¬æ¥èŠèŠå…³äºâ€œ${scene.title}â€çš„æ•…äº‹å§ã€‚è¯·é—®ï¼Œå…³äºè¿™ä¸ªä¸»é¢˜ï¼Œæ‚¨æœ€å…ˆæƒ³åˆ°çš„æ˜¯ä»€ä¹ˆï¼Ÿ`;
    setCurrentAIQuestion(firstQuestion);
    speak(firstQuestion, () => setIsProcessing(false)); // è¯´å®Œåï¼Œå…è®¸ç”¨æˆ·å¼€å§‹å½•éŸ³

    return () => {
      Voice.destroy().then(Voice.removeAllListeners);
      Speech.stop();
    };
  }, []);

  // --- è¯­éŸ³è¯†åˆ« (STT) ---
  const onSpeechStart = () => setIsRecording(true);
  const onSpeechEnd = () => setIsRecording(false);
  const onSpeechError = (e) => {
    setError(JSON.stringify(e.error));
    setIsRecording(false);
  }
  const onSpeechResults = (e) => {
    const speechResult = e.value[0];
    setUserSpeech(speechResult);
    // å…³é”®ï¼šç”¨æˆ·è¯´å®Œåï¼Œç«‹å³å¤„ç†
    handleUserSpeech(speechResult);
  };
  
  const startRecognizing = async () => {
    if(isProcessing) return;
    setUserSpeech('');
    setError('');
    try {
      await Voice.start('zh-CN');
    } catch (e) {
      console.error(e);
    }
  };

  const stopRecognizing = async () => {
    try {
      await Voice.stop();
    } catch (e) {
      console.error(e);
    }
  };

  // --- æ–‡æœ¬è½¬è¯­éŸ³ (TTS) ---
  const speak = (text, onDoneCallback) => {
    Speech.speak(text, { language: 'zh-CN', onDone: onDoneCallback });
  };
  
  // --- æ ¸å¿ƒå¯¹è¯é€»è¾‘ ---
  const handleUserSpeech = async (speechText) => {
    setIsProcessing(true); // å¼€å§‹å¤„ç†ï¼Œç¦ç”¨éº¦å…‹é£

    // 1. æ›´æ–°å¯¹è¯å†å²
    const newHistory = [...conversationHistory, { role: 'user', content: speechText }];
    setConversationHistory(newHistory);
    
    // 2. è·å–AIçš„ä¸‹ä¸€ä¸ªé—®é¢˜ï¼Œä¼ é€’ä¸»é¢˜å‚æ•°
    const { next_question } = await getNextQuestion(newHistory, scene.title);
    
    // 3. æ›´æ–°AIé—®é¢˜å¹¶æœ—è¯»
    setCurrentAIQuestion(next_question);
    speak(next_question, () => {
        setIsProcessing(false); // AIè¯´å®Œåï¼Œå…è®¸ç”¨æˆ·å†æ¬¡å½•éŸ³
        setUserSpeech(''); // æ¸…ç©ºä¸Šä¸€è½®çš„ç”¨æˆ·å›ç­”
    });
  };

  const handleEndDialogue = async () => {
    setIsProcessing(true);
    // 1. ç”Ÿæˆæœ€ç»ˆæ•…äº‹ï¼Œä¼ é€’ä¸»é¢˜å‚æ•°
    const finalStory = await generateMemoir(conversationHistory, scene.title);
    
    // 2. ä¿å­˜æ•…äº‹åˆ°æœ¬åœ°
    await saveMemoir(finalStory);
    
    // 3. å¯¼èˆªåˆ°é¢„è§ˆé¡µ
    stopRecognizing();
    navigation.navigate('StoryPreview', { memoir: finalStory });
  };

  return (
    <SafeAreaView style={styles.safeArea}>
      <View style={styles.container}>
        <View style={styles.aiQuestionContainer}>
          {isProcessing && !isRecording ? (
            <ActivityIndicator size="large" color="#4A90E2" />
          ) : (
            <Text style={styles.aiQuestionText}>{currentAIQuestion}</Text>
          )}
        </View>

        <View style={styles.userSpeechContainer}>
          <Text style={styles.userSpeechText}>{userSpeech || (isRecording ? '...' : '')}</Text>
        </View>

        <View style={styles.micContainer}>
          <TouchableOpacity 
            style={[styles.micButton, (isRecording || isProcessing) && styles.micButtonDisabled]} 
            onPress={startRecognizing}
            disabled={isProcessing}
          >
            <Text style={styles.micIcon}>ğŸ¤</Text>
          </TouchableOpacity>
          <Text style={styles.micLabel}>
            {isProcessing ? 'AIæ­£åœ¨æ€è€ƒ...' : (isRecording ? 'æ­£åœ¨è†å¬...' : 'ç‚¹å‡»å¼€å§‹è¯´è¯')}
          </Text>
        </View>

        <TouchableOpacity style={styles.endButton} onPress={handleEndDialogue}>
          <Text style={styles.endButtonText}>èŠå®Œäº†ï¼Œç”Ÿæˆæˆ‘çš„æ•…äº‹</Text>
        </TouchableOpacity>
      </View>
    </SafeAreaView>
  );
};


const styles = StyleSheet.create({
  safeArea: {
    flex: 1,
    backgroundColor: '#FCF8F3',
  },
  container: {
    flex: 1,
    paddingHorizontal: 25,
    justifyContent: 'space-between',
    paddingBottom: 40,
  },
  aiQuestionContainer: {
    flex: 2,
    justifyContent: 'center',
    alignItems: 'center',
  },
  aiQuestionText: {
    fontSize: 28,
    fontWeight: 'bold',
    color: '#3A3A3A',
    textAlign: 'center',
    lineHeight: 45,
  },
  userSpeechContainer: {
    flex: 3,
    justifyContent: 'center',
    padding: 20,
    backgroundColor: '#FFFFFF',
    borderRadius: 15,
  },
  userSpeechText: {
    fontSize: 22,
    color: '#5B5B5B',
    lineHeight: 35,
    textAlign: 'center',
  },
  micContainer: {
    alignItems: 'center',
    marginTop: 40,
  },
  micButton: {
    width: width * 0.3,
    height: width * 0.3,
    borderRadius: (width * 0.3) / 2,
    backgroundColor: '#4A90E2',
    justifyContent: 'center',
    alignItems: 'center',
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 4 },
    shadowOpacity: 0.3,
    shadowRadius: 5,
    elevation: 8,
  },
  micButtonDisabled: {
    backgroundColor: '#BDBDBD', // ç¦ç”¨æ—¶ç°è‰²
  },
  micIcon: {
    fontSize: 50,
  },
  micLabel: {
    fontSize: 20,
    color: '#666',
    marginTop: 15,
  },
  endButton: {
    marginTop: 20,
    alignSelf: 'center',
    padding: 15,
  },
  endButtonText: {
    fontSize: 18,
    color: '#4A90E2',
    fontWeight: 'bold',
  },
});

export default DialogueScreen; 